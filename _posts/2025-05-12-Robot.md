---
title: Building the Mite
description: A rover from scratch for learning SLAM and robot AI
categories: [Projects, Programming, Robotics]
tags: [AI, Robot]
mermaid: true
meta_description: ""
keywords: ""
---

This is the first post about the Mite project and my first post on this blog about a robot so it will start with some introduction.

## Backstory

I've been fascinated with robots for as long as I can remember, and I was building robots since I was a kid. I had Lego Mindstorms and competed in the FIRST Lego League, I got a Parallax BOEbot kit and programmed it to do all sorts of things in BASIC. In college I repurposed the chassis to add a CMU Cam module and an ultrasonic distance sensor on a pan/tilt assembly and controlled the whole thing with a Raspberry Pi. At some point, that robot got disassembled and rebuilt into a simpler remote controlled robot with a claw on it, a one-day project to prepare a STEM demo for some children who would be visiting the university for a science fair.

{% include embed/youtube.html id='29jIY2eN7OA' %}

My robot projects effectively paused until around 2022 when my father and I started building a new robot with a 3D printed frame and four independantly-controlled wheels, LIDAR, RADAR, a camera with pan/tilt and incredible optical zoom, and a whole lot more. Unfortunately that robot project is on hold pending some design challenges and I started this project so I could work on the software elements in the meantime. That other robot will be posted here eventually.

## The Mite

I named it Mite because my objective was to make a minimal, compact robot with simple mechanics to serve as a test bed for the software and AI I want to prototype. This meant starting with an old generic 2WD robot kit I'd had paying around since college. It is the ubiquitous round 2WD turtle-style chassis made from black sheet metal, yellow wheels, and yellow gear motors. The kit as I found it featured a [Romeo control board](https://www.dfrobot.com/product-656.html) which is basically an old fashioned Ardunio Uno clone with convenient headers for servos and analog sensors as well as a full H-bridge. From here I started making a plan for the hardware and software.

**Hardware:**

- 2WD turtle chassis
- Romeo board handling DC motor control and servos
- Raspberry Pi handling communications and sensors
- LD06 LIDAR
- A010 depth camera
- Raspberry Pi camera
- Servos with pan-tilt to aim the LIDAR and cameras

**Software:**

- Arduino sketch for the Romeo board
- Control program for the Raspberry Pi
- Dashboard/Server program for the AI workstation
- SLAM for navigation
- Point cloud collection for mesh reconstruction offline
- Multi-modal AI agent to control the robot

Unsurprisingly, half the motivation behind this project is to use my [VulcanAI](https://stevengann.com/posts/VulcanAI/) project to allow a self-hosted agentic AI to control the robot, but that will require a lot of infrastructure first.

## Firmware

The first step was to get the Romeo board up and running to control the rover's motors and eventually the servos too. I had played with this chassis and board in college so I knew it was pretty simple to get working, but I was curious how well [AI would handle the task](https://stevengann.com/posts/Vibe-Coding/). I fed the Arduino and Romeo documentation to Cursor and gave it a thorough description of what I needed. To summarize, I wanted it to accept commands over UART and decode them to set the motors and servos. Cursor spat out some very straight-forward Arduino code that did exactly what I needed. Not micro-optimized or terse, but not spaghetti code either. Considering Arduino was designed for students, hobbyists, and rapid prototyping, I am not surprised but still pleased with how well it worked. For something so simple and tedious, it is nice to offload the boilerplate to automation.

## Software

Next came the code for the Raspberry Pi. Because I am lazy I wanted the software to be cross-platform and run on my Windows workstation, Linux laptop, and Raspberry Pi equally well. Since the more elaborate sensors like LIDAR and cameras are all USB, it is convenient to test them directly on the system I am coding on. I could do this with C++, Python, or any number of other languages and platforms, but my favorite [golden hammer](https://en.wikipedia.org/wiki/Law_of_the_instrument) is still C#, especially as .NET has evolved to be an excellent cross-platform solution even on low-power SoCs like the anemic Raspberry Pi 3 I am using.

### Microcontroller Interface

Since this is a bottom-up sort of project, the software began with a class to interact with the Romeo board, sending it commands and reading back telemetry. Talking to a microcontroller over UART from C# is something I've done a million times already, so I decided to offload it to Cursor again. I wrote out the class skeleton with the public methods I required, then gave the AI agent a paragraph describing what the class should do and a reminder that it needed to be cross-platform between Linux and Windows. I know from experience that serial ports on Windows and Linux are quite different even with the .NET API abstracting away so much, so I was pleased when the AI's code intellgently checked if the platform was Linux-based and checked the `/dev` directory for variants of `/dev/ttyACM` and `/dev/ttyUSB`, something I vividly recall dealing with in both C# and Python years ago and had no desire to fuss with it again. Overall, the rest of the class was pretty straight-forward, partially because Cursor had access to the Arduino sketch for reference.

At this point I am just getting greedy, because the most annoying part of USB COM ports is figuring out what the device will be named, since it will be named differently on everything I plug it into. I asked Cursor to add some logic to automate this, and in a single step it added a query/response to the Arduino sketch and added a method to query all the USB serial ports and check for the response. Not a very novel solution, but a reliable one that works well enough.

### LIDAR Interface

This is where I put my Software Architect hat on. I know from the start that I will be using a 2D LIDAR module, but I have goals of using the 2D LIDAR to collect 3D LIDAR data, as well as more distant goals of using a 3D depth camera, 1D distance sensors, and a 3D RADAR module I recently received. Most importaly, I want to be able to pool all of this data for 2D and 3D mapping and autonomous navigation. With only 2D LIDAR on the immediate aggenda but so many possibilities to explore later, I wanted to keep the software modular so I define an `ISensor2D` interface. It allows a sensor object to have angular and linear offsets relative to the robot, and it outputs one or more 2D points of detected obstacles relative to the robot's position on a 2D plane aligned with the robot. For future expansion to 3D data I will add an interface like `ISensor3D` and have a simple wrapper that takes an `ISensor2D` as well as a 3D rotation and offset to translate 2D points into 3D. This will be essential when I try using the 2D LIDAR for 3D scanning by moving it on a pan/tilt assembly.

Again, the actual interaction with the LIDAR module is something I have done before in both Python and C#, and while my previous code wasn't suitable for reuse in this project, it was a good basis to rewrite to the `ISensor2D` interface. And again, rewriting old code to a new interface isn't something I was keen on spending much time on so I tasked Cursor with it. I fed it the LD06 datasheet, the wonderful [write-up by James Gibbard](https://gibbard.me/lidar/), and the Python and C# I had written and debugged previously. Sure enough, the AI had no trouble rewritting my code to fit the new interface. As I reviewed the AI's code (as you should always do with AI-generated content) I noticed a handful of small changes such as a thread-safe buffer for the data, and it even implemented decoding for a few fields in the LIDAR's output that I had ignored. It simply followed the structure and format of my code and continued it according to the information in the datasheet. Fabulous.



